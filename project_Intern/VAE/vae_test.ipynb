{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=200):\n",
    "        \"\"\"\n",
    "        Input shape: (bs, 1, 28, 28)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2),  # 13\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2), # 5\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 6 * 6, 2 * latent_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 7 * 7 * 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (32, 7, 7)),\n",
    "            nn.ConvTranspose2d(32, 64, kernel_size=3, stride=2, padding=1, output_padding=1), # 14\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1), # 28\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=1, padding=1), # 28\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = th.exp(0.5 * log_var)\n",
    "        eps = th.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu, log_var = th.chunk(x, 2, dim=-1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x = self.decoder(z)\n",
    "        return x, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
    "# device = th.device('cpu')\n",
    "model = VAE(28 * 28, 2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\지완\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (4.1.1)\n",
      "Requirement already satisfied: sympy in c:\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = datasets.MNIST(root='./dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(img):\n",
    "    plt.imshow(img.squeeze().numpy(), cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "show_image(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model: nn.Module, optimizer: th.optim.Optimizer, reconst_loss: nn.Module, train_loader: DataLoader, epochs: int, device: th.device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        desc = f'Epoch {epoch + 1}/{epochs}'\n",
    "        prograss_bar = tqdm(enumerate(train_loader), desc=desc, leave=False)\n",
    "        for batch_idx, (data, _) in prograss_bar:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output, mu, log_var = model(data)\n",
    "            rec_loss = reconst_loss(output, data)\n",
    "            kl_div = -0.5 * th.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            loss = rec_loss + kl_div\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            prograss_bar.set_postfix({'loss': loss.item() / len(data)})\n",
    "    return train_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(28 * 28, 2).to(device)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "final_loss = train(model, optimizer, loss_fn, train_loader, 10, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\지완\\Documents\\nlp\\project_Intern\\VAE\\vae_test.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%EC%A7%80%EC%99%84/Documents/nlp/project_Intern/VAE/vae_test.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%EC%A7%80%EC%99%84/Documents/nlp/project_Intern/VAE/vae_test.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%EC%A7%80%EC%99%84/Documents/nlp/project_Intern/VAE/vae_test.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m plot_latent_images(model, \u001b[39m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_latent_images(model, n, digit_size=28):\n",
    "    norm = th.distributions.Normal(0, 1)\n",
    "    grid_x = norm.icdf(th.linspace(0.05, 0.95, n))\n",
    "    grid_y = norm.icdf(th.linspace(0.05, 0.95, n))\n",
    "    image_width = digit_size * n\n",
    "    image_height = image_width\n",
    "    image = th.zeros(image_height, image_width)\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z = th.tensor([[xi, yi]]).to(device)\n",
    "            x_hat = model.decoder(z)\n",
    "            image[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = x_hat[0].reshape(digit_size, digit_size)\n",
    "    plt.imshow(image.detach().cpu().numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_latent_images(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
