{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq #1\n",
    "## LSTM Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus_books (/home/bluesun/.cache/huggingface/datasets/opus_books/en-fr/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4ba37ad81349de8de17103e65d358f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"opus_books\", \"en-fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 127085\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/bluesun/.cache/huggingface/datasets/opus_books/en-fr/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf/cache-4db7d380261ba335.arrow and /home/bluesun/.cache/huggingface/datasets/opus_books/en-fr/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf/cache-575547be2463d3f6.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 101668\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 25417\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '58398',\n",
      " 'translation': {'en': 'All this only increased the derision and hooting.',\n",
      "                 'fr': 'De tout cela, les dérisions et les huées s’accrurent.'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(dataset['train'][100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 15:33:52.787590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 15:33:52.856548: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-29 15:33:53.172137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bluesun/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/dan/anaconda3/lib/:/home/dan/anaconda3/lib/python3.8/site-packages/tensorrt/:/home/dan/anaconda3/envs/tf/lib:/home/dan/anaconda3/envs/tf/lib/python3.8/site-packages/tensorrt/\n",
      "2023-03-29 15:33:53.172179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bluesun/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/dan/anaconda3/lib/:/home/dan/anaconda3/lib/python3.8/site-packages/tensorrt/:/home/dan/anaconda3/envs/tf/lib:/home/dan/anaconda3/envs/tf/lib/python3.8/site-packages/tensorrt/\n",
      "2023-03-29 15:33:53.172182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-29 15:33:53.467093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 15:33:53.467261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bluesun/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/dan/anaconda3/lib/:/home/dan/anaconda3/lib/python3.8/site-packages/tensorrt/:/home/dan/anaconda3/envs/tf/lib:/home/dan/anaconda3/envs/tf/lib/python3.8/site-packages/tensorrt/\n",
      "2023-03-29 15:33:53.480675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bluesun/devel/lib:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/dan/anaconda3/lib/:/home/dan/anaconda3/lib/python3.8/site-packages/tensorrt/:/home/dan/anaconda3/envs/tf/lib:/home/dan/anaconda3/envs/tf/lib/python3.8/site-packages/tensorrt/\n",
      "2023-03-29 15:33:53.480710: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "fr_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', ',', 'the', '!', 'they', \"'re\", '~']\n",
      "['All', 'this', 'only', 'increased', 'the', 'derision', 'and', 'hooting', '.']\n",
      "['De', 'tout', 'cela', ',', 'les', 'dérisions', 'et', 'les', 'huées', 's’', 'accrurent', '.']\n"
     ]
    }
   ],
   "source": [
    "print(en_tokenizer(\"The, the! they're ~\"))\n",
    "print(en_tokenizer('All this only increased the derision and hooting.'))\n",
    "print(fr_tokenizer('De tout cela, les dérisions et les huées s’accrurent.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "def preprocess_text(examples):\n",
    "    en_text = examples['translation']['en'].lower()\n",
    "    fr_text = examples['translation']['fr'].lower()\n",
    "    \n",
    "    en_text = re.sub(f'[^\\w\\d\\s{re.escape(string.punctuation)}]', ' ', en_text)\n",
    "    fr_text = re.sub(f'[^\\w\\d\\s{re.escape(string.punctuation)}]', ' ', fr_text)\n",
    "    en_text = re.sub(r'\\s+', ' ', en_text)\n",
    "    fr_text = re.sub(r'\\s+', ' ', fr_text)\n",
    "    \n",
    "    return {'en': en_text, 'fr': fr_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/bluesun/.cache/huggingface/datasets/opus_books/en-fr/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf/cache-d39203dc4f653b77.arrow\n",
      "Loading cached processed dataset at /home/bluesun/.cache/huggingface/datasets/opus_books/en-fr/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf/cache-dc02ff54ee4d7ea6.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess_text, remove_columns=['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'en', 'fr'],\n",
       "        num_rows: 101668\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'en', 'fr'],\n",
       "        num_rows: 25417\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'all this only increased the derision and hooting.',\n",
      " 'fr': 'de tout cela, les dérisions et les huées s accrurent.',\n",
      " 'id': '58398'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(dataset['train'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <bos> : begin of sentence\n",
    "# <eos> : end of sentence\n",
    "# <unk> : unknown word\n",
    "# <pad> : padding\n",
    "\n",
    "vocabs = {'en': build_vocab_from_iterator(map(en_tokenizer, dataset['train']['en']), \n",
    "                                          specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "                                          min_freq=3),\n",
    "          'fr': build_vocab_from_iterator(map(fr_tokenizer, dataset['train']['fr']), \n",
    "                                          specials=['<unk>', '<pad>', '<bos>', '<eos>'],\n",
    "                                          min_freq=3)}\n",
    "\n",
    "vocabs['en'].set_default_index(vocabs['en']['<unk>'])\n",
    "vocabs['fr'].set_default_index(vocabs['fr']['<unk>'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the size of the vocab is too large, it will be difficult to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24596, 30224)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs['en']), len(vocabs['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and integer encode the text\n",
    "import torch as th\n",
    "\n",
    "SRC_LANG = 'fr'\n",
    "TGT_LANG = 'en'\n",
    "\n",
    "def encode_data(examples):\n",
    "    src_text = examples[SRC_LANG]\n",
    "    tgt_text = examples[TGT_LANG]\n",
    "    \n",
    "    src_tokenized = [vocabs[SRC_LANG]['<bos>']] + \\\n",
    "                    [vocabs[SRC_LANG][token] for token in en_tokenizer(src_text)] + \\\n",
    "                    [vocabs[SRC_LANG]['<eos>']]\n",
    "    \n",
    "    tgt_tokenized = [vocabs[TGT_LANG]['<bos>']] + \\\n",
    "                    [vocabs[TGT_LANG][token] for token in fr_tokenizer(tgt_text)] + \\\n",
    "                    [vocabs[TGT_LANG]['<eos>']]\n",
    "    \n",
    "    return {SRC_LANG: src_tokenized, TGT_LANG: tgt_tokenized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a01fa2243f4dda8b7fd2ae3a37d926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/101668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5d25a5440a44228dd73ab0e10cfe0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(encode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '58398', 'en': [2, 46, 39, 93, 1140, 5, 11926, 9, 11360, 6, 3], 'fr': [2, 6, 58, 116, 4, 13, 26751, 7, 13, 10947, 73, 21754, 5, 3]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', 'all', 'this', 'only', 'increased', 'the', 'derision', 'and', 'hooting', '.', '<eos>']\n",
      "['<bos>', 'de', 'tout', 'cela', ',', 'les', 'dérisions', 'et', 'les', 'huées', 's', 'accrurent', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print([vocabs['en'].get_itos()[i] for i in tokenized_dataset['train'][100]['en']])\n",
    "print([vocabs['fr'].get_itos()[i] for i in tokenized_dataset['train'][100]['fr']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for sampled_data in batch:\n",
    "        src_batch.append(th.tensor(sampled_data[SRC_LANG]))\n",
    "        tgt_batch.append(th.tensor(sampled_data[TGT_LANG]))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=vocabs[SRC_LANG]['<pad>'])\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=vocabs[TGT_LANG]['<pad>'])\n",
    "    return src_batch, tgt_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = data.DataLoader(tokenized_dataset['train'], batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "test_dataloader = data.DataLoader(tokenized_dataset['test'], batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Integer endoed tokens to embedding\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    vocab_size: int\n",
    "        Number of the vocabulary (= size of the dictionary)\n",
    "    embed_size: int\n",
    "        Size of the embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, emb_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb_dim = emb_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [bs, seq_len] or [seq_len, bs]\n",
    "        return self.embedding(x.long()) * np.sqrt(self.emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Encoder\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    vocab_size: int\n",
    "        Number of the vocabulary (= size of the dictionary)\n",
    "    emb_dim: int\n",
    "        Size of the embedding\n",
    "    hidden_dim: int\n",
    "        Size of the hidden dimension\n",
    "    n_layers: int\n",
    "        Number of the layers\n",
    "    dropout: float\n",
    "        Dropout rate\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 emb_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 n_layers: int,\n",
    "                 dropout: float):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = TokenEmbedding(vocab_size, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = [bs, seq_len]\n",
    "        embedded = self.embedding(x)    # [bs, seq_len, emb_dim]\n",
    "        hidden = self._init_hidden(x.shape[0])  # [n_layers, bs, hidden_dim]\n",
    "        outputs, hidden = self.rnn(embedded, hidden)\n",
    "        # outputs = [bs, seq_len, hidden_dim]\n",
    "        # hidden = [n_layers * 2, bs, hidden_dim]\n",
    "        return outputs, hidden\n",
    "    \n",
    "    def _init_hidden(self, batch_size: int):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state of the RNN to be zeros\n",
    "        \"\"\"\n",
    "        return th.zeros(self.n_layers, batch_size, self.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 emb_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 n_layers: int,\n",
    "                 dropout: float):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = TokenEmbedding(vocab_size, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(emb_dim * 2, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        # x = [bs, 1]\n",
    "        # hidden = [n_layers, bs, hidden_dim]\n",
    "        # encoder_outputs = [bs, seq_len, hidden_dim]\n",
    "        inputs = self.embedding(inputs)    # [bs, 1, emb_dim]\n",
    "        attn_weights = self._compute_attention(hidden, inputs).unsqueeze(1)    # [bs, 1, seq_len]\n",
    "        context = attn_weights.bmm(inputs)    # [bs, 1, hidden_dim]\n",
    "        context = th.cat((inputs, context), dim=2)    # [bs, 1, hidden_dim * 2]\n",
    "        outputs, hidden = self.rnn(context, hidden)\n",
    "        # outputs = [bs, 1, hidden_dim]\n",
    "        # hidden = [n_layers, bs, hidden_dim]\n",
    "        outputs = outputs.squeeze(1)    # [bs, hidden_dim]\n",
    "        outputs = self.fc(outputs)    # [bs, vocab_size]\n",
    "        return outputs, hidden, attn_weights\n",
    "    \n",
    "    def _compute_attention(self, outputs: th.Tensor, encoder_outputs: th.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the bahdanau attention\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        outputs: th.Tensor: [bs, 1, hidden_dim]\n",
    "            The outputs of the (decoder) RNN -> Query\n",
    "        encoder_outputs: th.Tensor: [bs, seq_len, hidden_dim]\n",
    "            The outputs of the encoder RNN -> Keys and Values\n",
    "        \"\"\"\n",
    "        # outputs = [bs, 1, hidden_dim]\n",
    "        # encoder_outputs = [bs, seq_len, hidden_dim]\n",
    "        seq_len = encoder_outputs.shape[1]\n",
    "        hidden_dim = encoder_outputs.shape[2]\n",
    "        outputs = outputs.repeat(1, seq_len, 1)     # [bs, seq_len, hidden_dim]\n",
    "        attn = self.attn(th.tanh(outputs + encoder_outputs)).squeeze(2)\n",
    "        # attn = [bs, seq_len]\n",
    "        return F.softmax(attn, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder: RNNEncoder,\n",
    "                 decoder: RNNDecoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing=0.5):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        src: th.Tensor: [bs, seq_len]\n",
    "            The source sentence\n",
    "        tgt: th.Tensor: [bs, seq_len]\n",
    "            The target sentence\n",
    "        teacher_forcing: float\n",
    "            The probability of using teacher forcing\n",
    "        \"\"\"\n",
    "        batch_size = src.shape[0]\n",
    "        tgt_len = tgt.shape[1]\n",
    "        tgt_vocab_size = self.decoder.fc.out_features\n",
    "        outputs = th.zeros(batch_size, tgt_len, tgt_vocab_size).to(src.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        # encoder_outputs = [bs, seq_len, hidden_dim]\n",
    "        # hidden = [n_layers, bs, hidden_dim]\n",
    "        \n",
    "        # First input to the decoder is the <sos> token\n",
    "        inputs = tgt[:, 0].unsqueeze(1)\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden, _ = self.decoder(inputs, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = th.random(1).item() < teacher_forcing\n",
    "            top1 = output.argmax(1, keepdim=True)\n",
    "            inputs = tgt[:, t].unsqueeze(1) if teacher_force else top1\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c99887877cf8154d7844f7dd912fc6fe217beebf8c55bc48bb11321ac59cf8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
